{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install python-decouple\n",
    "# !pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "from time import time, sleep\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import textwrap\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import TextFormatter\n",
    "# # from decouple import config   # this is usually enough to read configs in non-notebook environment\n",
    "# import decouple\n",
    "# config = decouple.AutoConfig('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = 'YOUR_OPENAI_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(url):\n",
    "    url_data = urlparse(url)\n",
    "    video_id = parse_qs(url_data.query)[\"v\"][0]\n",
    "    if not video_id:\n",
    "        print('Video ID not found.')\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        formatter = TextFormatter()\n",
    "\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
    "        text = formatter.format_transcript(transcript)\n",
    "        text = re.sub('\\s+', ' ', text).replace('--', '')\n",
    "        return video_id, text\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error downloading transcript:', e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        return infile.read()\n",
    "\n",
    "\n",
    "def save_file(content, filepath):\n",
    "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3_completion(prompt, model='text-davinci-003', temp=0.5, top_p=1.0, tokens=500, freq_pen=0.25, pres_pen=0.0, stop=['\\n']):\n",
    "    max_retry = 3\n",
    "    retry = 0\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                model=model,\n",
    "                prompt=prompt,\n",
    "                temperature=temp,\n",
    "                max_tokens=tokens,\n",
    "                top_p=top_p,\n",
    "                frequency_penalty=freq_pen,\n",
    "                presence_penalty=pres_pen,\n",
    "                stop=stop)\n",
    "            text = response['choices'][0]['text'].strip()\n",
    "            text = re.sub('\\s+', ' ', text)\n",
    "            if not text:\n",
    "                retry += 1\n",
    "                continue\n",
    "            filename = f'gpt3_{time()}.log'\n",
    "            with open(f'gpt3_logs/{filename}', 'w') as outfile:\n",
    "                outfile.write('PROMPT:\\n\\n' + prompt + '\\n\\n==========\\n\\nRESPONSE:\\n\\n' + text)\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            retry += 1\n",
    "            if retry >= max_retry:\n",
    "                return \"GPT3 error: %s\" % e\n",
    "            print('Error communicating with OpenAI:', e)\n",
    "            sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(text, prompt_file, output_file, job='SUMMARY'):\n",
    "    # Summarize chunks\n",
    "    chunks = textwrap.wrap(text, width=10000)\n",
    "    results = list()\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        prompt = open_file(prompt_file).replace('<<CONTENT>>', chunk)\n",
    "        prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
    "        output = ''\n",
    "        if job=='SUMMARY':\n",
    "            output = gpt3_completion(prompt, tokens=500)\n",
    "        elif job == 'REWRITE':\n",
    "            output = gpt3_completion(prompt, tokens=2048)\n",
    "        results.append(output)\n",
    "        print(f'{i+1} of {len(chunks)}\\n{output}\\n\\n\\n')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/watch?v=kiMTRQXBol0&ab_channel=All-InPodcast'\n",
    "\n",
    "# Download transcript\n",
    "video_id, text = get_transcript(url)\n",
    "\n",
    "# Summarize the transcript (chunk by chunk if needed)\n",
    "if text:\n",
    "    # Summarize transcript\n",
    "    output_file = f'summary_{video_id}_{time()}.txt'\n",
    "    results = ask_gpt(text, '/work/prompt_summary.txt', 'SUMMARY')\n",
    "    summary = '\\n\\n'.join(results)\n",
    "    save_file(summary, output_file)\n",
    "\n",
    "    # Summarize the summary\n",
    "    if len(results) > 1:\n",
    "        new_summary = ask_gpt(summary, '/work/prompt_rewrite.txt', 'REWRITE')\n",
    "        save_file('\\n\\n'.join(new_summary), output_file.replace('.txt', '_2.txt'))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
